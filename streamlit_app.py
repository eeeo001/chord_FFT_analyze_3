import streamlit as st
import numpy as np
import librosa
import matplotlib.pyplot as plt
from scipy.fft import fft, fftfreq
from scipy.signal import find_peaks
from collections import defaultdict
import io
from audiorecorder import audiorecorder
import pandas as pd # pandas import ì¶”ê°€

# -----------------------------
# Streamlit Page Config
# -----------------------------
st.set_page_config(layout="wide")
st.title("FFT ê¸°ë°˜ ìë™ í™”ìŒ ì¸ì‹ (Automatic Chord Recognition)")
st.markdown("### í‘¸ë¦¬ì— ë³€í™˜ ë¶„ì„ì„ í†µí•´ ì˜¤ë””ì˜¤ ì‹ í˜¸ì—ì„œ í™”ìŒì„ ì‹ë³„í•©ë‹ˆë‹¤.")

# -----------------------------
# Utility: Frequency â†’ MIDI
# -----------------------------
def freq_to_midi(frequency):
    if frequency <= 0:
        return -1
    # 440 Hz (A4) is MIDI note 69
    midi_note = 69 + 12 * np.log2(frequency / 440.0)
    return int(round(midi_note))

# -----------------------------
# Utility: Harmonic Recommendation (í™”ì„±ì  ì¶”ì²œ)
# -----------------------------
# ì‹ë³„ëœ í™”ìŒê³¼ í™”ì„±ì ìœ¼ë¡œ ì˜ ì–´ìš¸ë¦¬ëŠ” ì½”ë“œ 3ê°œë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤. (ë‹¤ì´ì•„í† ë‹‰ ê¸°ë°˜)
def get_harmonic_recommendations(root_midi, chord_type, note_names):
    recommendations = []
    root_idx = root_midi % 12

    # I: Major, ii: Minor, iii: Minor, IV: Major, V: Dom7, vi: Minor (ë‹¤ì´ì•„í† ë‹‰ í™”ìŒ ê¸°ì¤€)
    
    if 'Major' in chord_type: # I (ìœ¼ëœ¸ í™”ìŒ)ìœ¼ë¡œ ê°„ì£¼
        # ì¶”ì²œ 1: IV Chord (ë²„ê¸ˆë”¸ë¦¼ í™”ìŒ)
        iv_root_idx = (root_idx + 5) % 12
        recommendations.append({'root_midi': iv_root_idx, 'chord_type': 'Major'})
        
        # ì¶”ì²œ 2: V7 Chord (ë”¸ë¦¼ í™”ìŒ - Dominant 7thë¡œ ì‚¬ìš©)
        v_root_idx = (root_idx + 7) % 12
        recommendations.append({'root_midi': v_root_idx, 'chord_type': 'Dominant 7th'})
        
        # ì¶”ì²œ 3: vi Minor Chord (ë‚˜ë€í•œ ì¡°ì˜ ìœ¼ëœ¸ í™”ìŒ - Submediant)
        vi_root_idx = (root_idx + 9) % 12
        recommendations.append({'root_midi': vi_root_idx, 'chord_type': 'Minor'})

    elif 'Minor' in chord_type: # i (ë‹¨ì¡° ìœ¼ëœ¸ í™”ìŒ)ìœ¼ë¡œ ê°„ì£¼
        # i, iv, V7, III (ë‹¨ì¡° í™”ìŒ ì§„í–‰ ê¸°ì¤€)
        
        # ì¶”ì²œ 1: iv Chord (ë²„ê¸ˆë”¸ë¦¼ ë‹¨ì¡° í™”ìŒ)
        iv_root_idx = (root_idx + 5) % 12
        recommendations.append({'root_midi': iv_root_idx, 'chord_type': 'Minor'})
        
        # ì¶”ì²œ 2: V7 Chord (ë”¸ë¦¼ í™”ìŒ - ë‹¨ì¡°ì—ì„œ ì£¼ë¡œ V7 ì‚¬ìš©)
        v_root_idx = (root_idx + 7) % 12
        recommendations.append({'root_midi': v_root_idx, 'chord_type': 'Dominant 7th'})
        
        # ì¶”ì²œ 3: III Chord (ë‚˜ë€í•œ ì¡°ì˜ ìœ¼ëœ¸ í™”ìŒ - Relative Major)
        III_root_idx = (root_idx + 3) % 12
        recommendations.append({'root_midi': III_root_idx, 'chord_type': 'Major'})
    
    else: # 7th, 9th ë“± ê¸°íƒ€ í™”ìŒ (Major Key Context ê¸°ì¤€ìœ¼ë¡œ ì¶”ì²œ)
        # ì¶”ì²œ 1: IV Chord
        iv_root_idx = (root_idx + 5) % 12
        recommendations.append({'root_midi': iv_root_idx, 'chord_type': 'Major'})
        
        # ì¶”ì²œ 2: V Chord
        v_root_idx = (root_idx + 7) % 12
        recommendations.append({'root_midi': v_root_idx, 'chord_type': 'Dominant 7th'})
        
        # ì¶”ì²œ 3: vi Chord
        vi_root_idx = (root_idx + 9) % 12
        recommendations.append({'root_midi': vi_root_idx, 'chord_type': 'Minor'})
        
    return recommendations[:3] # í•­ìƒ 3ê°œë§Œ ë°˜í™˜

# -----------------------------
# 1) Audio Recording Section
# -----------------------------
st.subheader("ğŸ¤ ì˜¤ë””ì˜¤ ë…¹ìŒ")

audio = audiorecorder("ë…¹ìŒ ì‹œì‘", "ë…¹ìŒ ì¤‘ì§€")
recorded_file = None

if len(audio) > 0:
    st.success("ë…¹ìŒ ì™„ë£Œ!")

    # Convert AudioSegment â†’ WAV bytes
    wav_buffer = io.BytesIO()
    audio.export(wav_buffer, format="wav")
    wav_bytes = wav_buffer.getvalue()

    # Playback
    st.audio(wav_bytes, format="audio/wav")

    # Save to variable for main analysis
    recorded_file = io.BytesIO(wav_bytes)
    recorded_file.name = "recorded_audio.wav"

# -----------------------------
# 2) File Uploader Section
# -----------------------------
st.subheader("ğŸ“ ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ")
uploaded_file = st.file_uploader("WAV/MP3 íŒŒì¼ ì—…ë¡œë“œ", type=['wav', 'mp3'])

# --- íŒŒì¼ ë¶„ì„ ì†ŒìŠ¤ ê²°ì • (ìˆ˜ì •ëœ ë¡œì§) ---
file_to_analyze = None

if uploaded_file is not None:
    # Priority 1: ì‚¬ìš©ìê°€ ìƒˆë¡œ ì—…ë¡œë“œí•œ íŒŒì¼ì´ ìˆë‹¤ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
    file_to_analyze = uploaded_file
elif recorded_file is not None:
    # Priority 2: ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ê³  ë…¹ìŒ íŒŒì¼ì´ ìˆë‹¤ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
    file_to_analyze = recorded_file
    
# -----------------------------
# No file yet
# -----------------------------
if file_to_analyze is None:
    st.info("ë¶„ì„ì„ ìœ„í•´ ì˜¤ë””ì˜¤ë¥¼ ë…¹ìŒí•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.stop()

# -----------------------------
# Begin Analysis
# -----------------------------
try:
    # Load audio data (file_to_analyze ì‚¬ìš©)
    y, sr = librosa.load(file_to_analyze, sr=None)

    st.success("ì˜¤ë””ì˜¤ ë¡œë“œ ì™„ë£Œ!")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("ìƒ˜í”Œë§ ì†ë„", f"{sr} Hz")
    with col2:
        st.metric("ê¸¸ì´", f"{len(y)/sr:.2f} ì´ˆ")

    # -----------------------------
    # FFT Calculation
    # -----------------------------
    N = len(y)
    yf = fft(y)
    xf = fftfreq(N, 1/sr)

    half_n = N // 2
    xf_positive = xf[:half_n]
    yf_positive = np.abs(yf[:half_n])

    # -----------------------------
    # Show Spectrum
    # -----------------------------
    st.subheader("ì£¼íŒŒìˆ˜ ìŠ¤í™íŠ¸ëŸ¼")

    fig, ax = plt.subplots(figsize=(10, 4))
    ax.plot(xf_positive, yf_positive)
    ax.set_title("Frequency Spectrum")
    ax.set_xlabel("Frequency (Hz)")
    ax.set_ylabel("Magnitude")
    ax.set_xlim([20, 2000]) # Display range for typical musical notes
    ax.grid(True)
    st.pyplot(fig)

    # -----------------------------
    # Peak Identification
    # -----------------------------
    # Filtering parameters
    magnitude_threshold = np.max(yf_positive) * 0.05
    frequency_resolution = sr / N
    min_freq_separation_hz = 10
    distance_bins = int(min_freq_separation_hz / frequency_resolution)

    peak_indices, _ = find_peaks(
        yf_positive,
        height=magnitude_threshold,
        distance=distance_bins
    )

    peak_frequencies = xf_positive[peak_indices]
    peak_magnitudes = yf_positive[peak_indices]

    # -----------------------------
    # Harmonic Filtering (Fundamental Frequency Isolation)
    # -----------------------------
    initial_sorted_peaks = sorted(
        zip(peak_magnitudes, peak_frequencies),
        key=lambda x: x[0],
        reverse=True
    )

    filtered_fundamentals = []
    tolerance = 0.015  # 1.5% for harmonic detection

    for mag, freq in initial_sorted_peaks:
        is_harmonic = False
        for fundamental_freq, _ in filtered_fundamentals:
            for n in range(2, 6):
                expected = fundamental_freq * n
                if abs(freq - expected) / expected < tolerance:
                    is_harmonic = True
                    break
            if is_harmonic:
                break
        if not is_harmonic:
            filtered_fundamentals.append((freq, mag))

    filtered_fundamentals.sort(key=lambda x: x[0])
    
    # ê·¼ìŒ ì£¼íŒŒìˆ˜ì™€ ê·¸ ê°•ë„ë¥¼ ë§¤í•‘í•˜ì—¬ ì‚¬ìš©
    fundamental_data = {
        freq_to_midi(f): m for f, m in filtered_fundamentals if f > 50
    }
    fundamental_midi_notes = list(fundamental_data.keys())


    # -----------------------------
    # Chord Detection (Collect all matching candidates)
    # -----------------------------
    note_names = ['C', 'C#', 'D', 'D#', 'E', 'F',
                  'F#', 'G', 'G#', 'A', 'A#', 'B']
    chord_templates = {
        'Major': [0, 4, 7],
        'Minor': [0, 3, 7],
        'Dominant 7th': [0, 4, 7, 10],
        'Major 7th': [0, 4, 7, 11],
        'Minor 7th': [0, 3, 7, 10],
        'Dominant 9th': [0, 4, 7, 10, 2],
        'Major 9th': [0, 4, 7, 11, 2],
        'Minor 9th': [0, 3, 7, 10, 2],
    }

    all_matches = []
    unique_fundamental_midi_notes = sorted(list(set(fundamental_midi_notes)))

    # Iterate through all fundamental notes as potential roots
    for root_midi in unique_fundamental_midi_notes:
        # Calculate intervals (0-11) relative to the current root_midi
        intervals = set((n - root_midi) % 12 for n in fundamental_midi_notes)
        
        # ê·¼ìŒì˜ ê°•ë„ (Magnitude of the root note)
        root_magnitude = fundamental_data.get(root_midi, 0)
        # ìµœëŒ€ ê°•ë„ (Max magnitude for normalization)
        max_magnitude = max(fundamental_data.values()) if fundamental_data else 1
        
        # ê·¼ìŒ ê°•ë„ë¥¼ 0.0 ~ 1.0 ì‚¬ì´ë¡œ ì •ê·œí™” (normalization)
        normalized_root_mag = root_magnitude / max_magnitude if max_magnitude > 0 else 0
        
        for chord_type, template in chord_templates.items():
            # 1. ê¸°ë³¸ì ì¸ ì¼ì¹˜ ì ìˆ˜: í…œí”Œë¦¿ì˜ ëª‡ ê°œ ìŒì´ ì˜¤ë””ì˜¤ì— ì¡´ì¬í•˜ëŠ”ê°€?
            match_count = sum(1 for t in template if t in intervals)
            
            # 2. ê·¼ìŒ ê°€ì¤‘ì¹˜ ë¶€ì—¬ (Weighting the score by root magnitude):
            # ê·¼ìŒ ê°•ë„ê°€ ë†’ì„ìˆ˜ë¡ ìµœì¢… ì ìˆ˜ì— ê°€ì¤‘ì¹˜ë¥¼ ë†’ê²Œ ë¶€ì—¬
            # *** ì—¬ê¸°ì„œ ê°€ì¤‘ì¹˜ë¥¼ 1.5ì—ì„œ 2.0ìœ¼ë¡œ ìƒí–¥ ì¡°ì •í–ˆìŠµë‹ˆë‹¤. ***
            weighted_score = match_count + (normalized_root_mag * 2.0) 
            
            # Store all valid matches (match_count 2 ë˜ëŠ” weighted_score 2 ì´ìƒ)
            if weighted_score >= 2.0:
                all_matches.append({
                    'score': weighted_score, # ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ì ìˆ˜ë¥¼ ì‚¬ìš©
                    'root_midi': root_midi,
                    'chord_type': chord_type,
                    'template_len': len(template) # Used for tie-breaking: prefer shorter templates
                })

    # Sort matches: 1. By weighted_score (highest first), 2. By template length (shorter/simpler first), 3. By root MIDI (deterministic)
    # Note the negative sign on template_len for ascending length preference
    all_matches.sort(key=lambda x: (x['score'], -x['template_len'], -x['root_midi']), reverse=True)
    
    # Remove duplicates where root_midi and chord_type are the same, prioritizing the best score
    unique_matches = []
    seen = set()
    for match in all_matches:
        identifier = (match['root_midi'], match['chord_type'])
        if identifier not in seen:
            unique_matches.append(match)
            seen.add(identifier)
            
    best_match = unique_matches[0] if unique_matches else None

    # í™”ì„±ì ìœ¼ë¡œ ì–´ìš¸ë¦¬ëŠ” ì½”ë“œ 3ê°œ ì¶”ì²œ
    if best_match:
        root_midi = best_match['root_midi']
        chord_type = best_match['chord_type']
        recommended_matches = get_harmonic_recommendations(root_midi, chord_type, note_names)
    else:
        recommended_matches = []


    # -----------------------------
    # Final Output Generation (with constituent notes and recommendations)
    # -----------------------------
    st.subheader("ğŸµ ìµœì¢… ì‹ë³„ ê²°ê³¼")

    if best_match:
        best_root_midi = best_match['root_midi']
        best_chord_type = best_match['chord_type']
        
        root_note = note_names[best_root_midi % 12]
        chord = f"{root_note} {best_chord_type}"
        
        # Calculate Chord Notes for Best Match
        template = chord_templates[best_chord_type]
        chord_note_indices = [((best_root_midi % 12) + interval) % 12 for interval in template]
        unique_chord_notes_names = [note_names[i] for i in sorted(list(set(chord_note_indices)))]
        notes_output = " - ".join(unique_chord_notes_names)
        
        st.markdown(f"### **âœ… ìµœì¢… ì‹ë³„ í™”ìŒ:** {chord}")
        st.metric(label="êµ¬ì„± ìŒì • (Constituent Notes)", value=notes_output)
        
        # Display Recommendations
        if recommended_matches:
            st.markdown("---")
            st.subheader("ğŸ’¡ ì¶”ê°€ ì¶”ì²œ í™”ìŒ (Top 3 Harmonically Fitting Candidates)")
            
            rec_data = []
            for match in recommended_matches:
                rec_root_midi = match['root_midi']
                rec_chord_type = match['chord_type']
                rec_root_note = note_names[rec_root_midi % 12]
                rec_chord = f"{rec_root_note} {rec_chord_type}"
                
                # Calculate Chord Notes for Recommendation
                # Use the global chord_templates dictionary
                rec_template = chord_templates.get(rec_chord_type, [0, 4, 7]) # Fallback to Major Triad
                rec_chord_note_indices = [((rec_root_midi % 12) + interval) % 12 for interval in rec_template]
                rec_unique_notes_names = [note_names[i] for i in sorted(list(set(rec_chord_note_indices)))]
                rec_notes_output = " - ".join(rec_unique_notes_names)
                
                # Append recommended chord and its constituent notes
                rec_data.append([rec_chord, rec_notes_output])
            
            # Create a simple table for recommendations (Changed st.table to st.dataframe and added hide_index=True)
            st.dataframe(
                pd.DataFrame(
                    rec_data, 
                    columns=['ì¶”ì²œ í™”ìŒ', 'êµ¬ì„± ìŒì •'] # Updated column name to 'êµ¬ì„± ìŒì •'
                ),
                hide_index=True # ì¸ë±ìŠ¤ ìˆ¨ê¸°ê¸°
            )

    else:
        chord = "No chord identified (í™”ìŒ ë¯¸ì‹ë³„)"
        st.markdown(f"### **âŒ {chord}**")
        st.metric(label="êµ¬ì„± ìŒì • (Constituent Notes)", value="N/A")
        st.info("ìµœì†Œ ì¼ì¹˜ ì ìˆ˜(2ì )ë¥¼ ì¶©ì¡±í•˜ëŠ” í™”ìŒ í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

except Exception as e:
    st.error(f"ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
